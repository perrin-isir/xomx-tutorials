{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/perrin-isir/xomx-tutorials/blob/main/tutorials/xomx_hla.ipynb\"> <img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open in Google Colaboratory\"></a>\n",
    "<a id=\"raw-url\" href=\"https://raw.githubusercontent.com/perrin-isir/xomx-tutorials/main/tutorials/xomx_hla.ipynb\" download> <img align=\"left\" src=\"https://img.shields.io/badge/Github-Download%20(Right%20click%20%2B%20Save%20link%20as...)-blue\" alt=\"Download (Right click + Save link as)\" title=\"Download Notebook\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *xomx tutorial:* **tissue prediction based on HLA-presented peptides**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:** This notebook runs best using a GPU runtime (for the variational autoencoder training).  \n",
    "In Colab: from the Colab menu, choose Runtime > Change Runtime Type, then select **'GPU'**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports:\n",
    "import os\n",
    "import sys\n",
    "import joblib\n",
    "from IPython.display import clear_output\n",
    "try:\n",
    "    import xomx\n",
    "except ImportError:\n",
    "    !pip install xomx\n",
    "    clear_output()\n",
    "    import xomx\n",
    "try:\n",
    "    import scanpy as sc\n",
    "except ImportError:\n",
    "    !pip install scanpy\n",
    "    clear_output()\n",
    "    import scanpy as sc\n",
    "try:\n",
    "    import trimap\n",
    "except ImportError:\n",
    "    !pip install trimap\n",
    "    clear_output()\n",
    "    import trimap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Give the possibility to force a plotting extension (bokeh or matplotlib) when running the code as a python script:\n",
    "if len(sys.argv) > 1 and sys.argv[1] in [\"bokeh\", \"matplotlib\"]:\n",
    "    xomx.pl.force_extension(sys.argv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = os.path.join(os.path.expanduser(\"~\"), \"results\", \"xomx-tutorials\", \"xomx_hla\")  # the default directory in which results are stored\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The HLA Ligand Atlas is a resource of natural HLA ligands presented on benign tissues.  \n",
    "We first gather in a dict (`dfs`) 4 pandas dataframes from the HLA Ligand Atlas: \n",
    "- `dfs[\"peptides\"]`: the list of peptide sequences with their id,\n",
    "- `dfs[\"donors\"]`: the list of donors and their alleles,\n",
    "- `dfs[\"sample_hits\"]`: for all the peptide sequences, the donors and tissues in which they have been found, and their HLA class,\n",
    "- `dfs[\"aggregated\"]`: one row per peptide sequence, with the HLA class of the peptide, and the list of donor alleles and tissues associated with the peptide. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"http://hla-ligand-atlas.org/rel/2020.12/\"\n",
    "filenames = [\"peptides\", \"donors\", \"sample_hits\", \"aggregated\"]\n",
    "dfs = {}\n",
    "for nm in filenames:\n",
    "    if not os.path.isfile(os.path.join(save_dir, nm + \".joblib\")):\n",
    "        dfs[nm] = pd.read_csv(base_url + nm + \".tsv.gz\", sep=\"\\t\")\n",
    "        joblib.dump(dfs[nm], os.path.join(save_dir, nm + \".joblib\"))\n",
    "    else:\n",
    "        dfs[nm] = joblib.load(os.path.join(save_dir, nm + \".joblib\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the set of all alleles present in the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alleles_ = sorted(list(set(np.concatenate([allele.split(\",\") for allele in dfs[\"aggregated\"].donor_alleles]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this list, the alleles start with one of the 3 prefixes \"n/\", \"w/\" and \"s/\", which characterize binding predictions of peptides:  \n",
    "- \"n/\": predicted non-binder donor allele\n",
    "- \"w/\": predicted weak binder donor allele\n",
    "- \"s/\": predicted strong binder donor allele\n",
    "\n",
    "For example, the peptide with id 22 has been found in donors with the following alleles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dfs[\"aggregated\"][dfs[\"aggregated\"].peptide_sequence_id == 22].donor_alleles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The peptide is predicted to be a non-binder for all of these alleles, except for DRB5\\*01:01, for which it is predicted to be a strong binder.  \n",
    "Here is the list of alleles without the prefixes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alleles = sorted(list(set([al[2:] for al in alleles_])))\n",
    "alleles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now filter the data to keep only peptides that are predicted to be weak or strong binders for the allele B\\*08:01:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_allele = \"B*08:01\"\n",
    "allele_filtered_df = dfs[\"aggregated\"][dfs[\"aggregated\"].donor_alleles.apply(lambda x: (\"w/\" + selected_allele in x) or (\"s/\" + selected_allele in x))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the set of tissues in the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tissues = set(np.concatenate([tissue.split(\",\") for tissue in dfs[\"aggregated\"].tissues]))\n",
    "tissues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select a few of them, for example \"Liver\", \"Lung\" and \"Ovary\", and filter the data to keep only the peptides that have been found in exactly one of these tissues (and not in several of these tissues):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_tissues = [\"Liver\", \"Lung\", \"Ovary\"]\n",
    "\n",
    "def filter_peptides(x):\n",
    "    return sum([tissue in x for tissue in selected_tissues]) == 1\n",
    "\n",
    "tissue_filtered_df = allele_filtered_df[allele_filtered_df.tissues.apply(filter_peptides)]\n",
    "print(f\"{len(tissue_filtered_df)} peptides\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an AnnData object with one-hot encodings of the peptides. The label attributed to a peptide is the name of the unique tissue (among the ones selected) in which it has been found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length_peptide = tissue_filtered_df.peptide_sequence.apply(len).max()\n",
    "xd = sc.AnnData(shape=(tissue_filtered_df.shape[0], max_length_peptide * len(xomx.tl.aminoacids)))\n",
    "xd.obs_names = np.array(tissue_filtered_df.peptide_sequence)\n",
    "xd.X = np.empty((xd.n_obs, xd.n_vars))\n",
    "for i in range(xd.n_obs):\n",
    "    xd.X[i, :] = xomx.tl.onehot(xd.obs_names[i], max_length_peptide)\n",
    "    \n",
    "def compute_label(x):\n",
    "    tissue_array = np.array([tissue if tissue in x else \"\" for tissue in selected_tissues])\n",
    "    return \"\".join(tissue_array)\n",
    "\n",
    "xd.obs['labels'] = np.array(tissue_filtered_df.tissues.apply(compute_label))\n",
    "xd.uns['all_labels'] = xomx.tl.all_labels(xd.obs['labels'])\n",
    "xd.uns['obs_indices_per_label'] = xomx.tl.indices_per_label(xd.obs['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's observe 2D embeddings of the data. First with the TRIMAP algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trim = trimap.TRIMAP()\n",
    "xd.obsm[\"trimap\"] = trim.fit_transform(xd.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xomx.pl.plot_2d_obsm(xd, \"trimap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then with a variational autoencoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we check the backend for JAX:\n",
    "import jax\n",
    "print(jax.lib.xla_bridge.get_backend().platform)\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "vae = xomx.em.BetaVAE(xd, n_components=2, random_state=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xd.obsm[\"vae\"] = vae.fit_transform(iterations=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xomx.pl.plot_2d_obsm(xd, \"vae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xomx.tl.train_and_test_indices(xd, \"obs_indices_per_label\", test_train_ratio=0.25, rng=rng)\n",
    "classifier = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tissue in selected_tissues:\n",
    "    classifier[tissue] = xomx.cl.ExtraTrees(\n",
    "        xd,\n",
    "        tissue,\n",
    "        n_estimators=450,\n",
    "        random_state=rng,\n",
    "    )\n",
    "    confusion_matrix = classifier[tissue].train()\n",
    "    print(tissue)\n",
    "    print(confusion_matrix)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier[\"Ovary\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xomx.tl.matthews_coef(classifier[\"Ovary\"].confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remark: the MCC score obtained is close to 0.5, which is definitely better than random predictions (MCC ~ 0), however for other choices of alleles and tissues, we frequently obtain an MCC score close to 0, showing that the classifier is not able to generalize at all.  \n",
    "The problem of tissue prediction based on HLA-presented peptides is hard, but there may be specific cases for which it is possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbm = xomx.cl.ScoreBasedMulticlass(xd, xd.uns[\"all_labels\"], classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbm.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To avoid quitting at the end of the tutorial if the code is executed as a python script:\n",
    "embed()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
